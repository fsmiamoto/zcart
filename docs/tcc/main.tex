%% Exemplo de utilizacao do estilo de formatacao normas-utf-tex (http://normas-utf-tex.sourceforge.net)
%% dúvidas acessar o site acima
%%
%%
%% Autores: (200?-2011) Hugo Vieira Neto (hvieir@utfpr.edu.br)
%%          (200?-2011) Diogo Rosa Kuiaski (diogo.kuiaski@gmail.com)
%%          (2011-2017) Marcos Talau <talau@users.sourceforge.net>
%% Colaborador:
%%          (2011) César M. Vargas Benitez <cesarvargasb@gmail.com>

%%
%% IMPORTANTE: O texto está escrito com acentuação antiga, atualmente você
%%             pode escrever acentos sem precisar de códigos para tal.
%%

\documentclass[openright]{normas-utf-tex} %openright = o capitulo comeca sempre em paginas impares
%\documentclass[oneside]{normas-utf-tex} %oneside = para dissertacoes com numero de paginas menor que 100 (apenas frente da folha) 

% force A4 paper format
\special{papersize=210mm,297mm}

\usepackage[alf,abnt-emphasize=bf,bibjustif,recuo=0cm, abnt-etal-cite=2, abnt-etal-list=99]{abntcite} %configuracao correta das referencias bibliograficas.

\usepackage[utf8]{inputenc} % pacote para acentuacao direta
\usepackage{amsmath,amsfonts,amssymb} % pacote matematico
\usepackage{graphicx} % pacote grafico
\usepackage[final]{pdfpages} % adicao da ata
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    frame=tb,
    tabsize=2
}

\lstset{style=mystyle}

% ---------- Preambulo ----------
\instituicao{Federal University of Technology - Paraná} % nome da instituicao
\programa{Department of Electronics} % nome do programa
\area{Electronics Engineering} % [Engenharia Biomedica] ou [Informatica Industrial] ou [Telematica]

\documento{Undergraduate Thesis}
\nivel{Bacharelado} % [Mestrado] ou [Doutorado]
\titulacao{Bacharel} % [Mestre] ou [Doutor]

\titulo{{zCart: A smart cart prototype}} % titulo do trabalho em portugues
\title{\MakeUppercase{zCart: A smart cart prototype}} % titulo do trabalho em ingles

\autor{Flávio Shigueo Miamoto} % autor do trabalho
\autordois{João Pedro Zanlorensi Cardoso} % autor do trabalho
\cita{MIAMOTO, Flavio; ZANLORENSI, Joao Pedro} % sobrenome (maiusculas), nome do autor do trabalho

\palavraschave{Artificial Inteligenge, Deep Learning, Smart Devices, Internet of Things} 

\comentario{\UTFPRdocumentodata\ presented to the \UTFPRprogramadata\ of the \ABNTinstituicaodata\ as a partial requisite for obtaining the Bachelor in Electronics Engineering degree}

\orientador{André Eugênio Lazaretti, Ph.D}

\local{Curitiba} % cidade
\data{\the\year} % ano automatico

% desativa hifenizacao mantendo o texto justificado.
% thanks to Emilio C. G. Wille
\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000
\sloppy

%---------- Inicio do Documento ----------
\begin{document}

\capa % geracao automatica da capa
\folhaderosto % geracao automatica da folha de rosto

% dedicatoria
\begin{dedicatoria}
    Add dedicatoria
\end{dedicatoria}

% agradecimentos (opcional)
\begin{agradecimentos}
    Add agradecimentos
\end{agradecimentos}

% epigrafe (opcional)
\begin{epigrafe}
 If have seen further it is by standing on the shoulders of giants.  \\
- Sir Isaac Newton
\end{epigrafe}

%abstract
\begin{abstract}
Abstract text (maximum of 500 words).
\end{abstract}

% listas (opcionais, mas recomenda-se a partir de 5 elementos)
\listadefiguras % geracao automatica da lista de figuras
\listadetabelas % geracao automatica da lista de tabelas
% \listadequadros % adivinhe :)
\listadesiglas % geracao automatica da lista de siglas
\listadesimbolos % geracao automatica da lista de simbolos

% sumario
\sumario % geracao automatica do sumario


%---------- Inicio do Texto ----------
% recomenda-se a escrita de cada capitulo em um arquivo texto separado (exemplo: intro.tex, fund.tex, exper.tex, concl.tex, etc.) e a posterior inclusao dos mesmos no mestre do documento utilizando o comando \input{}, da seguinte forma:
%\input{intro.tex}
%\input{fund.tex}
%\input{exper.tex}
%\input{concl.tex}

\setcounter{page}{12}

\chapter{Introduction}

With the advancement of high speed mobile networks and smartphone penetration,
customer demands are on an ever increasing trajectory for more personalized
and digital experiences. In that regard, companies worldwide are fighting for customer
attention in the digital era by developing products and services that bring state-of-the-art technologies
to the masses in the so called smart devices and systems \cite{Shafique2020}.

As an example of such advancements, smart speakers such as the Amazon Echo \cite{GaoPanWangChen2018} include the latest and greatest
in terms of Natural Language Processing and Deep Learning \cite{Young2018}, allowing customers to interact with the product in an conversational manner
that was considered to be science fiction material until a couple of years ago.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.4\textwidth]{./images/echodot4.jpg} % <- formatos PNG, JPG e PDF
	\caption[Amazon Echo 4th Generation smart speaker promotional material]{Amazon Echo 4th Gen Smart Speaker promotional material}
    \fonte{Amazon (2022)}
	\label{fig:echodot4}
\end{figure}

\begin{quote}
    \textit{This device is a gem! When I’m busy in the kitchen, for example, and can’t get
    to a computer to find info or music to play, Alexa would be there to listen
    and do what I ask.} \\
    Customer review from \cite{GaoPanWangChen2018}
\end{quote}

Alongside the devices themselves, entirely new markets have emerged such as the third-party software extensions
called \textit{Alexa Skills} \cite{Alexa2022}.

These skills function much like mobile phone apps, extending and enhancing the
functionality of the device and can be sold to users.

Developers are can then leverage the highly advanced machine learning models - which can be notoriously expensive to develop 
and maintain \cite{Phdata2021} - through \sigla{API}{Application Programming Interface}s and focus exclusively on their application logic.

\begin{figure}[htb!]
	\centering
	\includegraphics[width=0.9\textwidth]{./images/skills.png} % <- formatos PNG, JPG e PDF
	\caption[Diagram showing the steps of an interaction with an Alexa Skill]{Diagram showing the steps of an interaction with an Alexa Skill}
    \fonte{\cite{Alexa2022}}
	\label{fig:alexaskill}
\end{figure}

More impressively, such technological advancements have been able to reach a considerable amount of households in
a short period in developed countries like the United States, a display of the power of the economy of scale and how
an extensible ecosystem can boost sales.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{./images/smartspeaker.png} % <- formatos PNG, JPG e PDF
	\caption[US Smart Speaker Penetration from 2017 to 2022]{US Smart Speaker Penetration from 2017 to 2022}
    \fonte{\cite{InsiderIntelligence2022}}
	\label{fig:smartspeaker}
\end{figure}

On developing countries, such as Brazil, these innovations tend to have delayed
arrivals due to historical economic barriers but the potential customer base
has attracted big tech companies, along with their economic power, shortening the
delay.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\textwidth]{./images/alexabr.jpg} % <- formatos PNG, JPG e PDF
	\caption[Localized promotional material for the Echo Show 10 targeting Brazilian customers]{Localized promotional material for the Echo Show 10 targeting Brazilian customers}
    \fonte{Amazon (2022)}
    \label{fig:alexabr}
\end{figure}

According to the research company IDC Brasil, the home automation market - in
which smart speakers are included - would have reached US\$ 298 million on
2021, an impressive figure.

Although these advancements might seem entirely beneficial at first, countless
challenges have been found regarding privacy, ethical handling of personal
customer data and overall negative experiences caused by increased
dependencies, e.g what happens when you lose internet connection?

These discussions are of the utter most importance given our current scenario
and have been brought up by recent literature \cite{Echoes2022,He2019}
but will be out of the scope of this work.

\section{Motivation}

Even with all of these innovations impacting customer behaviors day by day, one
important aspect of consumer life still hasn't had any significant changes in
the last couple of years: \textbf{grocery shopping on
physical stores}.

According to \sigla{ABRAS}{Associação Brasileira de Supermercados} - the
Brazilian Supermarket Association - the grocery retail sector has reached an
impressive total revenue of \textbf{R\$ 611 billion} in 2021 - roughly US\$ 117 billion on
October 2022 - making up 7.03\% of the national \sigla{GDP}{Gross
Domestic Product}. About \textbf{28 million} customers visit one of the more than
\textbf{92,000} stores countrywide on a daily basis \cite{Abras2022}.

In the recent pandemic scenario, innovations such as the adoption of e-commerce platforms and
self-checkout solutions had their adoption increased in 2020 but 2021 showed that consumers have
mostly shifted back to their pre-pandemic behavior, favoring physical retail stores \cite{Kantar2022}.

But in such an economic relevant market and with all the technological
advancement we've been seing, most of the physical retail customers still
report pain points related to visiting a store. In a survey conducted in 2019,
Capgemini has found out five key problems \cite{Capgemini2020}:

\begin{enumerate}
        \item Long queues for payment checkout
        \item Out of stock products
        \item Difficulties in locating products in the store
        \item Not being able to find a store associate to help
        \item Lack of product information when I select products
\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/painpoints.png}
    \caption[Top five customer pain points in retail stores]{Top five customer pain points in retail stores}
    \fonte{\cite{Capgemini2020}}
    \label{fig:capgemini}
\end{figure}

More interestingly, Figure \ref{fig:capgemini} shows that at least half of the
survey respondents believe that all of the five pain points can be solved through
\textbf{automation}.

It is in this scenario of customer pain and enormous market potential that this
thesis will explore a technological solution to improve customer experience,
namely the \textbf{smart shopping cart}.

\section{Current scenario}

In this next section, we'll explore some of the existing solutions and how they
try to improve customer experience and increase the retailer's revenue.

\subsection{Caper Cart}

Developed by the Caper\footnote{https://caper.ai} company, the Caper Cart was the worlds's first AI-powered smart cart \cite{Caper2020}

The first version was launched in 2017 and offered grocers the
great advantage of not requiring any infrastructure overhaul for deployment.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/capercartui.png}
	\caption[Caper Cart user interface]{Caper Cart user interface}
    \fonte{Caper (2020)}
	\label{fig:caperui}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/caper.png}
	\caption[Caper Cart at a retail store]{Caper Cart at a retail store}
    \fonte{Caper (2020)}
	\label{fig:caperatretail}
\end{figure}

For customers, it offered visual product recognition and a payment terminal,
allowing customers to avoid the dreaded queues by the end of their shopping.
Additionally, customers were able to search products, get discounts and locate
items more easily with the help of the user interface provided by the cart.

Although Caper does not publicize the cost of each cart, it is estimate that each unit costs between
\textbf{US\$ 5,000 and 10,000} \cite{TWP2021}.

Acquired by Instacart\footnote{https://instacart.com} in 2021 for US\$ 350 million, Caper is developing in 2022 the 
third version of its Smart Shopping Cart, advertising an increase in \textbf{65\% in the basket
volume} and a \textbf{10 month} breakeven.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/capercart3.png}
	\caption[Caper Cart 3 promotional material]{Caper Cart 3 promotional material}
    \fonte{Caper (2022)}
	\label{fig:nextop}
\end{figure}


\subsection{Amazon Dash Cart}

Available at the Amazon Fresh\footnote{https://www.amazon.com/fmc/m/30003175?almBrandId=QW1hem9uIEZyZXNo} retail chain, the
Amazon Dash Cart.

According to Amazon, it uses computer vision and sensors to allow customers to
simply add items to their cart which already accounts all the items and
subtotal. By the end of their item selection, customers can check-out
automatically without having to go through queues, solving the biggest customer
pain point pointed out by Capgemini.

\begin{quote}
\textit{Looking to make grocery trips quicker? With the Amazon Dash Cart you can skip the checkout line and roll out to your car when you are done.}

\textit{The Dash cart uses a combination of computer vision algorithms and sensor fusion to help identify items placed in the cart - simply grab an item, scan it on one of the Dash Cart cameras, and place it in the cart like you normally would.}
\\
Amazon (2022)
\end{quote}R

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/dashcart.png}
    \caption[Amazon Dash Cart]{Amazon Dash Cart}
    \fonte{Amazon (2022)}
    \label{fig:dashcart}
\end{figure}

Additionally, the user interface provided by the Cart allows customers to search for item location and see more information
about them, improving the customer experience.

One of its quircks is that it requires the download and usage of an mobile phone app for using the cart, in contrast
to Caper's Cart.

As of October 2022, the Amazon Dash Cart is exclusively available at the Amazon
Fresh chain and therefore no commercial information regarding cost per unit is
available.

\subsection{Nextop}

Founded in 1997, Nextop\footnote{https://nextop.com.br} is a Brazilian company
that develops products with a focus on the grocer market with an emphasis on
loss prevention.

According to the company, the Smart Cart Nextop is the first smart cart
deployed in Brazil and Latin America and was initially rolled out to the Enxuto
supermarket chain, present in the São Paulo state, on 2022 \cite{Paraiba2022}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{./images/nextop.jpeg}
	\caption[Smart Cart Nextop® deployed to a Brazilian supermarket]{Smart Cart Nextop® deployed to a Brazilian supermarket}
    \fonte{Nextop (2022)}
	\label{fig:nextop}
\end{figure}

Differently than the carts developed by Amazon and Caper, Nextop's cart
requires customers to first scan the product using the integrate bar code
reader, as shown on Figure \ref{fig:nextopui}. This way, the product advertises
\textit{triple validation} using the cameras, sensors and the barcode scanner \cite{Nextop2022}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{./images/nextop2.png}
    \caption[Smart Cart Nextop® user interface with a payment terminal]{Smart Cart Nextop® user interface with a payment terminal}
    \fonte{\cite{Paraiba2022}}
	\label{fig:nextopui}
\end{figure}

Although it pleases grocers with the improved loss prevention, the usage of the barcode scanner creates in our opinion a worse
end customer experience, becoming a sort of \textit{mobile checkout station}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{./images/nextoppromo.png}
    \caption[Smart Cart Nextop® promotinal material targetting supermarket owners]{Smart Cart Nextop® promotinal material targetting supermarket owners}
    \fonte{\cite{Nextop2022}}
	\label{fig:nextopui}
\end{figure}

Besides offering the improve shopping experience by not having to go through queues by the end of the trip, the product advertises increased sales
as a result of the innovative approach and also allows a deeper understanding of the customer journey by collecting analytical data \cite{Paraiba2022}.

\begin{quote}
\textit{We are offering our customers an innovative and unique shopping experience within Enxuto}

\textit{With the smart cart, we broke through this barrier and managed to monitor the
entire customer's purchase circuit in the physical store. We have moved
from the identified ticket era to the end-to-end identified journey}

    Bruno Bragancini Junior, \sigla{CEO}{Chief Executive Officer} of the Enxuto Group \cite{Paraiba2022}
\end{quote}


This goes in line with the
company's know how on loss prevention which appeared to be an important aspect
of the product for the target Brazilian customer base.


According to Nextop's CEO, Juliano Camargo, the company has already invested \textbf{R\$ 8.5 million} - about US\$ 1.63 million on October 2022 - and \textbf{4 and half years}
of research and development.

Each Smart Cart is estimated to cost around \textbf{R\$ 120,000  or around US\$ 23,020} on October 2022 \cite{Paraiba2022}.

\section{Expected outcomes}

After presenting the problem domain and the current solutions, in this section we discuss the expected
outcomes of this work, mainly:

\textit{Develop a prototype of a smart shopping cart, including a mechanical assembly using with computer vision for object recognition
and an interactive user interface}

In a more granular level, these outcomes are also expected:

\begin{itemize}
    \item Collect a product dataset for traning a deep learning model
    \item Train a Deep Learning model capable of detecting target products
	\item Learn the practical challenges of developing a Deep Learning based product
    \item Understand the economic viability of such a project in the Brazilian context
\end{itemize}

Given our time and financial constraints, it is expected that the final results will yield
a solution with unsolved challenges, but a functional version is expected.

\chapter{Theoretical Background}

In this section, we'll define in greater detail some most relevant techniques
used in the development of our prototype.

This section can be skipped for readers with familiarity on the topics discussed

\section{Deep Learning}

\section{Neural Networks}

\section{Load Cell}

\section{HX711}

The HX711 is a 24-bit analog-to-digital converter (\sigla{ADC}{Analog-to-Digital Converter})
capable of outputting data in a Serial Interface (ADD CITATION).

It has two channels for analog input with channel A having programable gains of 128 or 64.

For power supply, it can be used with both 3.3\simbolo{V}{Volts} and 5 V standard digital voltages.

One of its advantages is is that there's no need to program internal registers, all
controls to the chip are through its pins.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/hx711-pinout.png}
	\caption[HX711 Pinout for the SOP-16L package]{HX711 Pinout for the SOP-16L package}
    \fonte{\cite{Avia2022}}
	\label{fig:architecture}
\end{figure}

\chapter{Development}
\label{chap:desenv}

\section{Design}
\label{sec:design}

As a first step in developing our prototype, a set of
responsibilities was established to guide the high level design and is listed below:

\begin{enumerate}
    \item Handle user interactions and give visual feedback
    \item Store the current set of products present in the cart and their respective information
    \item Recognize the addition or removal of products through computer vision and sensorial data.
\end{enumerate}

With those responsabilities in mind, the high level architecture of the prototype
was designed and is shown in Figure \ref{fig:architecture}.

For each responsability, a separate software application will be used and those
applications will communicate using \sigla{TCP}{Transmission Control Protocol}
network sockets \cite{Kurose2013} with established application protocols such as
\sigla{HTTP}{Hypertext Transfer Protocol}\footnote{First defined in
\sigla{RFC}{Request For Comments} 1945} -- using the RESTful pattern -- and
WebSocket\footnote{Defined in RFC 6455}.

For handling the first responsability, the \textit{User App} will request data
from other applications and will display the information to end users and allow
them to interact with the cart using a touch enabled LCD display.

The \textit{Cart Service} will be in charge of the second responsability,
handling requests from the \textit{User App} that request data or incur in any
side effects, such as finalizing a purchase. The \textit{Cart Service} uses a
\textbf{relational database} \cite{Silberschatz2010} as its datastore. Namely
\textbf{SQLite}, considered to be the worlds most deployed database due to its
massive adoption in mobile
devices\footnote{https://www.sqlite.org/mostdeployed.html}. The simplicity of
SQLite -- the entire database is contained within a single file -- great
library support in common programming languages and the use of the familiar
relational modeling, including \sigla{SQL}{Structured Query Language}
\cite{Nield2016}, were key factors in choosing it.

All three applications will executed under a Linux \cite{Tanenbaum2015} based environment on a Raspberry Pi\footnote{https://www.raspberrypi.com} 4 Single Board
Computer (\sigla{SBC}{Single Board Computer}) - a complete computer built on a single circuit board with microprocessor, memory and input/output devices.

The advantages of using a Linux environment for the development are many, but
being able to leverage its concurrency capabilities, having built-in drivers
for readily available hardware and leveraging open source projects are some to
mention.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/zCart.png}
	\caption[High level architecture of zCart]{High level architecture of zCart}
	\fonte{Own work}
	\label{fig:architecture}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/E2E.png}
	\caption[End-to-end sequence diagram for a product addition]{End-to-end sequence diagram for a product addition}
	\fonte{Own work}
	\label{fig:e2eseq}
\end{figure}

\subsection{Architectural Guidelines}
In creating the zCart architecture, the following guidelines were followed:

\begin{itemize}
    \item Create a separate software application for each responsability
    \item Use well defined standards for communication between applications.
    \item All databases should be owned by a single application. 
    \item Any interaction that requires an update to a given database that is
        not owned by an application should be done through an API and not
        directly.
    \item Decouple the user interface from the how the data displayed is stored and transmitted
\end{itemize}

These guideline are based on known best practices from the software development industry including API-first design and segregation of
responsabilities. \cite{Sam2021,Kong2022}

In the sections that follow, each application will be further detailed.

\section{User App}

For developing the User App, we have used web technologies such as HTML, CSS \cite{Duckett2011} and JavaScript \cite{Flanagan2020} through the 
React\footnote{htps://reactjs.org} framework. 

Using web based technologies allows the User App to be display on any device capable of running a web browser and
having mature tooling for development, testing and debugging influenced our decision.

Although developing Linux native graphical applications through toolkits such
as GTK\footnote{https://gtk.org} and Qt\footnote{https://qt.io} might have
yield better performance, our familiarity with web based technologies was a
key deciding factor in favor of using those.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/ui.png}
	\caption[User App Interface display a single product]{User App Interface displaying a single product}
	\fonte{Own work}
	\label{fig:userapp}
\end{figure}

As shown on Figure \ref{fig:userapp}, the main objective of the User App is to
provide a visual feedback mechanism for end users of the zCart.

It displays the current products added to the cart, the quantity and also the
price for each item. The subtotal for all products added to the cart is
calculated and also displayed on the interface. Notifications are also
displayed when the user adds or removes a product from the cart. Finally, the
User App provides a \textit{Checkout} button to simulate the payment process
and act as a Proof-of-Concept (\sigla{PoC}{Proof-of-Concept}) but a functional implementaion is out of scope
for the the zCart prototype.

More screenshots are available in Appendix \ref{ap:userapp}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/lcddisplay.jpeg}
	\caption[LCD Display showing the User App during development]{LCD Display showing the User App during development}
	\fonte{Own work}
	\label{fig:dummy}
\end{figure}

In terms of the data flow, the User App requests all data from the Cart Service, which exposes API endpoints for
getting the list of products of a given cart, establishing a WebSocket connection for notifications and performing
the PoC checkout.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/diagrams/UserApp.png}
	\caption[User App and Cart Service interactions]{User App and Cart Service interactions}
	\fonte{Own work}
	\label{fig:dummy}
\end{figure}

\section{Cart Service}

As described in Section \ref{sec:design}, the Cart Service will act as a
centralized \textit{source of truth}, storing the overall \textbf{state} of the
cart.

For that it will responsible for managing the SQLite database and exposing API
endpoints for the required state changes e.g. adding a product.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/diagrams/CartService.png}
	\caption[Cart Service architecture]{Cart Service architecture. The database is contained withing the Cart Service boundary and it is not exposed in the public APIs}
	\fonte{Own work}
	\label{fig:dummy}
\end{figure}

For the HTTP endpoints, the Application uses the REST \cite{Roy2000} pattern
with JavaScript Object Notation (\sigla{JSON}{JavaScript Object
Notation})\footnote{https://json.org} as the data-interchange format, both
being widely used in the current software industry.

As example response is show at Listing \ref{lst:response}.

\begin{table}[H]
	\centering
	\label{tab:correlacao}
	\begin{tabular}{c|c|c}
		\hline 
        HTTP Method & URI & Description \\
		\hline
        \texttt{GET} & \texttt{/cart/:cartId} & Get the cart data with the product listing \\
        \texttt{POST} & \texttt{/cart/:cartId/products} & Add or remove a product from the cart \\
        \texttt{POST} & \texttt{/cart/:cartId/checkout} & Perform checkout, emptying the cart \\
		\hline 
	\end{tabular}
	\caption[Cart Service API endpoints]{Cart Service API Endpoints}
	\fonte{Own work}
\end{table}

\begin{lstlisting}[caption={Example response for the \texttt{GET /cart/:cartId} endpoint using JSON},label={lst:response}]
{
  "id": "1",
  "products": [
    {
      "cart_id": "1",
      "product_id": "1",
      "quantity": 11,
      "product": {
        "id": "1",
        "name": "Coca Cola",
        "description": null,
        "price": 5.99,
        "image_url": "https://zcart-test-images.s3.amazonaws.com/coca2l.png"
      }
    },
  ]
}
\end{lstlisting}

For the implementation, the Go\footnote{https://go.dev} language was used
alongside the Fiber\footnote{https://gofiber.io/} framework, which provides
great support for the creation of the HTTP Server and also handling the
WebSocket connections.

One of the advantages of the Go language is the use of statically compiled
native binaries, which allow running the application without the need to
install any additional operating system libraries.

\section{Product Recognizer}

At the core of the zCart prototype is the Product Recognizer application,
responsible for the product detection based on computer vision and weight
sensing.

For achieving its goal, the Product Recognizer has three main sub-components as shown below:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/diagrams/ProductRecognizer.png}
	\caption[]{}
	\fonte{Own work}
	\label{fig:dummy}
\end{figure}

Each of these sub-components will be described in more detail in the next subsections.

\subsection{Weight Sensor}

For the Weight Sensor, we've used two main hardware components, shown on Figure \ref{fig:weightcomponents}:
\begin{itemize}
    \item  A 10 Kg Load Cell
    \item HX711 Integrated Circuit
\end{itemize}

Both components are readily available at relatively low costs and therefore were chosen for
the project.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{./images/hx711.jpeg}
	\caption[HX711 breakout board and load cell]{HX711 breakout board and load cell}
	\fonte{Own work}
	\label{fig:weighttesting}
\end{figure}

The HX711 integrated circuited comes in a breakout board that contains the necessary passive components
and includes the pin headers for connecting with other boards.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/hx711circuit.png}
	\caption[Typical HX711 circuit]{Typical HX711 circuit}
    \fonte{\cite{Ross2019}}
\end{figure}

The Raspberri Pi board was connected to the HX711 through its GPIO pins,
allowing it to obtain the sensor readings through the a serial interface. The
protocol used does not follow any known standard \cite{Avia2022} and can be
described as a \textit{Non-i2c compliant two-wire
protocol}\footnote{https://github.com/queuetue/Q2-HX711-Arduino-Library}.

An open-source driver implementation was used\footnote{https://github.com/tatobari/hx711py} that
included all the necessary features for the prototype.

As shown on Figure \ref{fig:weighttesting}, the load cell requires a minimal
mechanical assembly to be tested properly, and for that two small wood plates
were used to secure the load cell and breakout board during development.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/raspberrypiwithloadcell.jpeg}
    \caption[Assembly used during development, including the Raspberry Pi, HX711 and load cell assembly]{Assembly used during development, including the Raspberry Pi, HX711 and load cell assembly}
	\fonte{Own work}
	\label{fig:dummy}
\end{figure}

\subsection{Camera}

In order to obtain a video feed to run Object Detection on, a camera system was
in required. For that, a standard consumer webcam was used for its reduced cost
and good operating system driver support.

The webcam used was a Microsoft LifeCam
Cinema\footnote{https://www.microsoft.com/pt-BR/accessories/products/webcams/lifecam-cinema},
capable of capturing video in 720p up to 30\sigla{FPS}{Frames per second}, more
than enough for our prototyping requirements.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{./images/webcam.jpg}
    \caption[Microsoft LifeCam Cinema Webcam used]{Microsoft LifeCam Cinema Webcam used}
	\fonte{Microsoft}
\end{figure}

\subsection{Application}

Developed in the Python\footnote{https://python.org} programming language, the
Product Recognizer application will provide the compute capabilities to apply
our business logic for processing the video feed provided by the camera and the
readings from the weight sensor.

The Python language was chosen for its vast tooling for working with computer
vision, sensors and interacting with the Raspberry Pi's built-in devices. The
language has also became a \textit{lingua franca} in the Machine Learning and
Data Science community as shown by volume of publications using it in the last
decade \cite{Wes2017,Joel2019,Andreas2016}.

To take advantage of the multiple processing cores available on the Raspberry
Pi 4 \sigla{SoC}{System on a chip}, the Product Recognizer application uses a
multi-threaded design to allow parallel processing, improving the overall
performance.

The three threads created are described below:
\begin{itemize}
    \item Frame Reader Thread: Responsible for reading frames from the Camera and making them available to the Main Thread.
    \item Main Thread: Responsible for bootstraping the application - including creating the other threads - and executed the main loop of
        object detection.
    \item Product Recognizer Thread: Responsible for applying the business logic using the objects detected and the weight sensor readings.
\end{itemize}

These threads communication in synchronous and asynchronous mechanisms to achieve the overall goal of processing video and sensor data, as
shown on Figure \ref{fig:threads}.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/Product Recognizer Thread communication.png}
	\caption[Thread communication for the Product Recognizer Appplication]{Thread communication for the Product Recognizer Application}
	\fonte{Own work}
	\label{fig:threads}
\end{figure}

\begin{lstlisting}[language=Python,caption={Loop of the Main Thread. Some details were ommitted for the sake of brevity},label={lst:main}]
while True:
  try:
    # Get frame from camera, provided by Frame Reader thread
    frame = stream.read_frame()

    # Preprocess and run object detection
    input = preprocessor.process(frame)
    detector.infer(input)

    # Filter objects by their class and confidence threshold
    objects = detector.get_objects()
    filtered_objects = object_filter.filter(objects)

    # Add filtered objects to the queue
    frame_objects_queue.put(filtered_objects)
\end{lstlisting}

As show on Listing \ref{lst:main} and on Figure \ref{fig:threads}, the Main
thread will do the computational work to fetch the frames from the camera that
were read by the Frame Reader thread, preprocess and run the object detection
model in it. The objects are then filtered and then added to a message queue
that will be used by the Product Recognizer thread to apply our business logic.

\subsection{Product Recognizer Thread}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/diagrams/framediff.png}
	\caption[Product Recognition diagram]{Product Recognition diagram}
	\fonte{Own work}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{./images/Product Recognizer Activity.png}
	\caption[Activity diagram for the Product Recognizer thread]{Activity diagram for the Product Recognizer thread}
	\fonte{Own work}
\end{figure}

\begin{lstlisting}[language=Python,caption={Product Recognizer thread logic}]
objects = self.queue.get_nowait()

# Preprocessing step just to format data
current_frame_objects = self.__build_object_dict(objects)

# Calculate the frame diff using the last and current frame objects
frame_diff = self.__get_frame_diff(
    current_frame_objects, self.last_frame_objects
)

if len(frame_diff) == 0:
    self.log.info("empty diff")
    continue

# Get current weight reading
weight_reading = self.weight_sensor.get_reading(samples=5)

for label, count in frame_diff.items():
    if not self.__valid_weight_difference(label, count, weight_reading):
        self.log.info("ignoring, not valid weight difference")
        continue

    # Send request to cart service
    self.__call_cart_service(label, count)

    # Update stored state
    self.last_weight_reading = weight_reading
    self.last_frame_objects[label] = current_frame_objects[label]
    if self.last_frame_objects[label] == 0:
        del self.last_frame_objects[label]
\end{lstlisting}

Given the frame object diff, it is then possible to calculate an expected
weight change based on the weight of each item - and their quantity - contained
in the diff. The expected weight difference is then compared with the actual
one obtained from the weight sensor

In this scenario, the weight readings are used as a filter and act as a
\textit{commit} step for differences detected in the frame objects.

\section{Mechanical Assembly}

For the mechinal assembly, a foldable utility cart was selected as a core
component with two additional wooden plates used for creating a \textit{false
bottom}. Between the plates, the load cell and Raspberry Pi board were secured
in place using bolts, screws and velcro.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{./images/cart.jpeg}
	\caption[Overall mechanical assembly including the LCD and Camera]{Overall mechanical assembly including the LCD and Camera}
	\fonte{Own work}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{./images/carttop.jpeg}
	\caption[Top view of the assembly showing the false bottom]{Top view of the assembly showing the false bottom}
	\fonte{Own work}
\end{figure}

Considering the objectives of the prototype, the shape of the mechanical
housing was not considered to be of great relevance and using a real
supermarket cart would be impractical for its size and cost. Still, we wanted
to keep a shape that would represent the overall idea of a smart cart.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{./images/cartbase2.jpeg}
	\caption[False bottom structure with the load cell and Raspberri in between]{False bottom structure with the load cell and Raspberri in between}
	\fonte{Own work}
\end{figure}

\chapter{Results}

\section{Challenges}

As one of the expected outcomes of our work, we been able to identify several
practical challenges that would need to be worked on for a marketable product and will be discussed
in the next sections.

\subsection{Extending the model for new products}
In a supermarket use case, we expect that products will need to be added or
removed from detection on a regular basis. That becomes a challenge when we
consider the amount of data necessary to train the model to the extend
described in this work and becomes a topic for future work.

\subsection{Deploying updates}

\subsection{Detecting the addition or removal of many products at once}

%---------- Referencias ----------
\clearpage % this is need for add +1 to pageref of bibstart used in 'ficha catalografica'.
\label{bibstart}
\bibliography{reflatex} % geracao automatica das referencias a partir do arquivo reflatex.bib
\label{bibend}

%---------- Apendices (opcionais) ----------
\apendice
\chapter{User App screenshots}
\label{ap:userapp}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/userapp.png}
	\caption[]{Product listing and subtotal}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/userapp2.png}
	\caption[]{Item addition notification}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/userapp3.png}
	\includegraphics[width=1\textwidth]{./images/userapp3.png}
	\caption[]{Item removal notification}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/userapp4.png}
	\caption[]{Pre-checkout confirmation popup}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{./images/userapp5.png}
	\caption[]{Post checkout screen}
\end{figure}
\end{document}
